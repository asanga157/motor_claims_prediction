# Motor Insurance Repair Cost Prediction

This project builds an end-to-end machine learning pipeline to **predict the expected repair cost of motor insurance claims** — the moment a customer first reports an accident.

Accurate FNOL-level repair cost prediction helps insurers:
- set early reserves more accurately
- prioritise claims handling and triage
- route claims to appropriate repair workflows
- identify anomalies and potential leakage early



---

## Use Case Overview

**Prediction Target**
- `Total_Repair_Cost`

## Repository Structure
conf/
pipelines/
src/
analysis/
logs/
job/
trash/
README.md
.gitignore


### Folder Details

#### `conf/`
YAML-based configuration files used across the project.
- feature definitions and thresholds
- model hyperparameters
- train/test split settings
- logging configuration

This allows behaviour changes without modifying code.

---

#### `pipelines/`
Executable **end-to-end pipelines** (CLI entrypoints).
- `data_pre_processing.py` – data cleaning, quality checks, filtering
- `model_training_pipeline.py` – feature engineering, model training, evaluation, explainability

These scripts orchestrate logic from `src/`.

---

#### `src/`
Core reusable Python modules (production-style).
- `data_preprocessing.py` – data quality flags and filtering logic
- `feature_engineering.py` – FNOL-safe feature engineering transformer
- `split.py` – train/test split logic
- `models.py` – model factory driven by config
- `metrics.py` – evaluation metrics (MAE, RMSE, MAPE, directional MAPE)
- `evaluation.py` – model comparison across train/test
- `explainability.py` – feature importance, permutation importance, SHAP utilities

All modeling logic lives here (not in notebooks).

---

#### `analysis/`
Optional notebooks and generated outputs (local only).
- used for EDA, debugging, and visual validation
- outputs such as evaluation tables and plots

This folder is typically ignored in version control.

---

#### `logs/`
Runtime logs generated by pipelines.
- useful for debugging and auditability
- excluded from Git

---

#### `job/`
folder which run's the sheduled jobs (deployed pipelines - when the model is running on a daily level)

---

## How to Run the End-to-End Pipeline

### 1) Environment Setup

```bash
python -m venv .venv
source .venv/bin/activate
pip install -U pip
pip install pandas numpy scikit-learn pyyaml matplotlib
pip install shap
```

###  2) Run Data Preprocessing

This step:

- parses types

- flags duplicates, invalid records, cost inconsistencies

- applies configurable filtering rules

- produces a clean FNOL-safe dataset

```bash
python -m pipelines.data_pre_processing \
  --input motor_repair_costs.csv \
  --mode strict
```

### Outputs

- analysis/outputs/df_enriched.csv

- analysis/outputs/df_filtered_strict.csv

- data quality reports (missingness, flag counts)

### 3) Run Model Training & Evaluation

This step:

- splits train/test data

- fits feature engineering on training data only (no leakage)

- evaluates multiple models

- selects the best model using business-aligned metrics

- generates feature importance


```bash
python -m pipelines.model_training_pipeline \
  --input analysis/outputs/df_filtered_strict.csv \
  --save_feature_importance
```

## Outputs

- model comparison table

- feature importance for the best-performing model

### Evaluation Metrics

Models are evaluated using:

- MAE (Mean Absolute Error)

- RMSE

- R²

- MAPE

- Overall MAPE 

- Directional MAPE (over-forecast vs under-forecast)



